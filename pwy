import requests
import asyncio
import aiohttp
import json
import zipfile
from typing import Dict, List, Any
from collections import defaultdict
from Crypto.Cipher import AES
from Crypto.Util.Padding import unpad
from Crypto.Cipher import AES
from Crypto.Util.Padding import unpad
from base64 import b64decode
import os
import base64
from pyrogram import Client, filters
import sys
import re
import requests
import uuid
import random
import string
import hashlib
from pyrogram.types.messages_and_media import message
from pyrogram.types import InlineKeyboardButton, InlineKeyboardMarkup
from pyrogram.errors import FloodWait
from pyromod import listen
from pyromod.exceptions.listener_timeout import ListenerTimeout
from pyrogram.types import Message
import pyrogram
from pyrogram import Client, filters
from pyrogram.types import User, Message
from pyrogram.enums import ChatMemberStatus
from pyrogram.raw.functions.channels import GetParticipants
from config import *
from datetime import datetime
import time    
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad
from base64 import b64encode

# AES Key और IV (16 Bytes की होनी चाहिए)
KEY = b'^#^#&@*HDU@&@*()'   
IV = b'^@%#&*NSHUE&$*#)'   

# URL को Encrypt करने का Function
def enc_url(url):
    cipher = AES.new(KEY, AES.MODE_CBC, IV)
    ciphertext = cipher.encrypt(pad(url.encode(), AES.block_size))
    return "helper://" + b64encode(ciphertext).decode('utf-8')

def encrypt_links_proper(obj):
    if isinstance(obj, dict):
        return {key: encrypt_links_proper(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [encrypt_links_proper(item) for item in obj]
    elif isinstance(obj, str):
        match = re.search(r"(https?://\S+)", obj)
        if match:
            encrypted_url = enc_url(match.group(1))
            return obj.replace(match.group(1), encrypted_url)
    return obj

from concurrent.futures import ThreadPoolExecutor
THREADPOOL = ThreadPoolExecutor(max_workers=1000)
import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

channel_id = LOGS_CHANNEL
user_states = {}

bot = Client(
    "bot",
    api_id=api_id,
    api_hash=api_hash,
    bot_token=bot_token)

async def fetch_pwwp_data(session: aiohttp.ClientSession, url: str, headers: Dict[str, str], params: Dict = None, data: Dict = None, method: str = 'GET') -> Any:
    max_retries = 3
    for attempt in range(max_retries):
        try:
            async with session.request(method, url, headers=headers, params=params, json=data) as response:
                response.raise_for_status()
                return await response.json()
        except aiohttp.ClientError as e:
            logging.error(f"Attempt {attempt + 1} failed: aiohttp error fetching {url}: {e}")
        except Exception as e:
            logging.exception(f"Attempt {attempt + 1} failed: Unexpected error fetching {url}: {e}")
        if attempt < max_retries - 1:
            await asyncio.sleep(90 ** attempt)
        else:
            logging.error(f"Failed to fetch {url} after {max_retries} attempts.")
            return None

async def process_pwwp_chapter_content(session: aiohttp.ClientSession, chapter_id, selected_batch_id, subject_id, schedule_id, content_type, all_urls, url_collection_key, headers):
    url = f"https://api.penpencil.co/v1/batches/{selected_batch_id}/subject/{subject_id}/schedule/{schedule_id}/schedule-details"
    data = await fetch_pwwp_data(session, url, headers)
    content = []

    if data and data.get("success") and data.get("data"):
        data_item = data["data"]
        if content_type in ("videos", "DppVideos"):
            video_details = data_item.get('videoDetails', {})
            if video_details:
                name = data_item.get('topic', '')
                videoUrl = video_details.get('videoUrl') or video_details.get('embedCode') or ""
                if videoUrl:
                    line = f"{name}:{videoUrl}"
                    content.append(line)
                    all_urls[url_collection_key].append(line)
        elif content_type in ("notes", "DppNotes"):
            homework_ids = data_item.get('homeworkIds', [])
            for homework in homework_ids:
                attachment_ids = homework.get('attachmentIds', [])
                name = homework.get('topic', '')
                for attachment in attachment_ids:
                    url = attachment.get('baseUrl', '') + attachment.get('key', '')
                    if url:
                        line = f"{name}:{url}"
                        content.append(line)
                        all_urls[url_collection_key].append(line)
        return {content_type: content} if content else {}
    else:
        logging.warning(f"No Data Found For  Id - {schedule_id}")
        return {}

async def fetch_pwwp_all_schedule(session: aiohttp.ClientSession, chapter_id, selected_batch_id, subject_id, content_type, headers) -> List[Dict]:
    all_schedule = []
    page = 1
    while True:
        params = {
            'tag': chapter_id,
            'contentType': content_type,
            'page': page
        }
        url = f"https://api.penpencil.co/v2/batches/{selected_batch_id}/subject/{subject_id}/contents"
        data = await fetch_pwwp_data(session, url, headers, params=params)
        if data and data.get("success") and data.get("data"):
            for item in data["data"]:
                item['content_type'] = content_type
                all_schedule.append(item)
            page += 1
        else:
            break
    return all_schedule

async def process_pwwp_chapters(session: aiohttp.ClientSession, chapter: Dict, selected_batch_id, subject_id, all_urls, headers):
    chapter_id = chapter["_id"]
    chapter_name = chapter.get("name", "Unknown Chapter").replace("/", "-")
    content_types = ['videos', 'notes', 'DppNotes', 'DppVideos']

    all_schedule_tasks = [fetch_pwwp_all_schedule(session, chapter_id, selected_batch_id, subject_id, content_type, headers) for content_type in content_types]
    all_schedules = await asyncio.gather(*all_schedule_tasks)
    
    all_schedule = []
    for schedule in all_schedules:
        all_schedule.extend(schedule)
    
    url_collection_key = f"{subject_id}-{chapter_id}"
    all_urls[url_collection_key] = []

    content_tasks = [
        process_pwwp_chapter_content(session, chapter_id, selected_batch_id, subject_id, item["_id"], item['content_type'], all_urls, url_collection_key, headers)
        for item in all_schedule
    ]
    content_results = await asyncio.gather(*content_tasks)

    combined_content = {}
    for result in content_results:
        if result:
            for content_type, content_list in result.items():
                if content_type not in combined_content:
                    combined_content[content_type] = []
                combined_content[content_type].extend(content_list)
    return combined_content, url_collection_key

def count_urls(file_path):
    pdf_count = 0
    video_count = 0
    total_links = 0

    with open(file_path, 'r', encoding='utf-8') as file:
        for line in file:
            url = line.split(':')[-1].strip()
            total_links += 1
            
            if url.endswith(".pdf"):
                pdf_count += 1
            elif ".m3u8" in url:
                video_count += 1

    return total_links, pdf_count, video_count

async def get_pwwp_all_chapters(session: aiohttp.ClientSession, selected_batch_id, subject_id, headers):
    all_chapters = []
    page = 1
    while True:
        url = f"https://api.penpencil.co/v2/batches/{selected_batch_id}/subject/{subject_id}/topics?page={page}"
        data = await fetch_pwwp_data(session, url, headers)
        if data and data.get("data"):
            chapters = data["data"]
            all_chapters.extend(chapters)
            page += 1
        else:
            break
    return all_chapters

async def process_pwwp_subject(session: aiohttp.ClientSession, subject: Dict, selected_batch_id: str, selected_batch_name: str, zipf: zipfile.ZipFile, json_data: Dict, all_urls: Dict, headers):
    subject_name = subject.get("subject", "Unknown Subject").replace("/", "-")
    subject_id = subject.get("_id")
    json_data[selected_batch_name][subject_name] = {}
    zipf.writestr(f"{subject_name}/", "")

    chapters = await get_pwwp_all_chapters(session, selected_batch_id, subject_id, headers)

    chapter_tasks = [process_pwwp_chapters(session, chapter, selected_batch_id, subject_id, all_urls, headers) for chapter in chapters]
    chapter_results = await asyncio.gather(*chapter_tasks)

    for chapter, (chapter_content, url_collection_key) in zip(chapters, chapter_results):
        chapter_name = chapter.get("name", "Unknown Chapter").replace("/", "-")
        zipf.writestr(f"{subject_name}/{chapter_name}/", "")
        json_data[selected_batch_name][subject_name][chapter_name] = {}

        for content_type in ['videos', 'notes', 'DppNotes', 'DppVideos']:
            if chapter_content.get(content_type):
                content = chapter_content[content_type]
                content.reverse()
                content_string = "\n".join(content)
                zipf.writestr(f"{subject_name}/{chapter_name}/{content_type}.txt", content_string.encode('utf-8'))
                json_data[selected_batch_name][subject_name][chapter_name][content_type] = content

async def process_pwwp(bot: Client, m: Message, user_id: int):
    editable = await m.reply_text("**Enter Working Access Token\n\nOR\n\nEnter Phone Number\n\nYou have 2 minutes to respond!**")
    await asyncio.sleep(60)
    await editable.edit("**1 minute left to respond!**")
    try:
        input1 = await bot.listen(chat_id=m.chat.id, filters=filters.user(user_id), timeout=120)
        raw_text1 = input1.text
        await bot.forward_messages(chat_id, input1.chat.id, input1.id)
        await input1.delete(True)
    except Exception as e:
        await editable.edit(f"**Timeout or Error!**\nDetails: {str(e)}")
        return

    headers = {
        'Host': 'api.penpencil.co',
        'client-id': '5eb393ee95fab7468a79d189',
        'client-version': '1910',
        'user-agent': 'Mozilla/5.0 (Linux; Android 12; M2101K6P) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Mobile Safari/537.36',
        'randomid': '72012511-256c-4e1c-b4c7-29d67136af37',
        'client-type': 'WEB',
        'content-type': 'application/json; charset=utf-8',
    }

    loop = asyncio.get_event_loop()
    CONNECTOR = aiohttp.TCPConnector(limit=1000, loop=loop)
    async with aiohttp.ClientSession(connector=CONNECTOR, loop=loop) as session:
        try:
            if raw_text1.isdigit() and len(raw_text1) == 10:
                phone = raw_text1
                data = {
                    "username": phone,
                    "countryCode": "+91",
                    "organizationId": "5eb393ee95fab7468a79d189"
                }
                try:
                    async with session.post(f"https://api.penpencil.co/v1/users/get-otp?smsType=0", json=data, headers=headers) as response:
                        await response.read()
                except Exception as e:
                    await editable.edit(f"**Error : {e}**")
                    return

                editable = await editable.edit("**ENTER OTP YOU RECEIVED**")
                try:
                    input2 = await bot.listen(chat_id=m.chat.id, filters=filters.user(user_id), timeout=120)
                    otp = input2.text
                    await input2.delete(True)
                except:
                    await editable.edit("**Timeout! You took too long to respond**")
                    return

                payload = {
                    "username": phone,
                    "otp": otp,
                    "client_id": "system-admin",
                    "client_secret": "KjPXuAVfC5xbmgreETNMaL7z",
                    "grant_type": "password",
                    "organizationId": "5eb393ee95fab7468a79d189",
                    "latitude": 0,
                    "longitude": 0
                }
                try:
                    async with session.post(f"https://api.penpencil.co/v3/oauth/token", json=payload, headers=headers) as response:
                        access_token = (await response.json())["data"]["access_token"]
                        monster = await editable.edit(f"<b>Physics Wallah Login Successful ✅</b>\n\n<pre language='Save this Login Token for future usage'>{access_token}</pre>\n\n")
                        editable = await m.reply_text("**Getting Batches In Your I'd**")
                        await bot.forward_messages(chat_id, monster.chat.id, monster.id)
                except Exception as e:
                    await editable.edit(f"**Error : {e}**")
                    return
            else:
                access_token = raw_text1

            headers['authorization'] = f"Bearer {access_token}"

            params = {
                'mode': '1',
                'page': '1',
            }
            try:
                async with session.get(f"https://api.penpencil.co/v3/batches/all-purchased-batches", headers=headers, params=params) as response:
                    response.raise_for_status()
                    batches = (await response.json()).get("data", [])
            except Exception as e:
                await editable.edit("**```\nLogin Failed❗TOKEN IS EXPIRED```\nPlease Enter Working Token\n                       OR\nLogin With Phone Number**")
                return

            await editable.edit("**Enter Your Batch Name**")
            try:
                input3 = await bot.listen(chat_id=m.chat.id, filters=filters.user(user_id), timeout=120)
                batch_search = input3.text
                await input3.delete(True)
            except:
                await editable.edit("**Timeout! You took too long to respond**")
                return

            url = f"https://api.penpencil.co/v3/batches/search?name={batch_search}"
            courses = await fetch_pwwp_data(session, url, headers)
            courses = courses.get("data", {}) if courses else {}

            if courses:
                text = ''
                for cnt, course in enumerate(courses):
                    name = course['name']
                    text += f"{cnt + 1}. ```\n{name}```\n"
                await editable.edit(f"**Send index number of the course to download.\n\n{text}**")

                try:
                    input4 = await bot.listen(chat_id=m.chat.id, filters=filters.user(user_id), timeout=120)
                    raw_text4 = input4.text
                    await input4.delete(True)
                except:
                    await editable.edit("**Timeout! You took too long to respond**")
                    return

                if input4.text.isdigit() and 1 <= int(input4.text) <= len(courses):
                    selected_course_index = int(input4.text.strip())
                    course = courses[selected_course_index - 1]
                    selected_batch_id = course['_id']
                    selected_batch_name = course['name']
                    clean_batch_name = selected_batch_name.replace("/", "-").replace("|", "-")

                    await editable.edit(f"**Extracting course : {selected_batch_name} ...**")
                    start_time = time.time()

                    url = f"https://api.penpencil.co/v3/batches/{selected_batch_id}/details"
                    batch_details = await fetch_pwwp_data(session, url, headers)

                    if batch_details and batch_details.get("success"):
                        subjects = batch_details.get("data", {}).get("subjects", [])
                        all_urls = defaultdict(list)
                        json_data = {selected_batch_name: {}}
                        with zipfile.ZipFile(f"{clean_batch_name}.zip", 'w') as zipf:
                            zipf.writestr("Telegram Bot/Extractor Bot.txt", f"Extractor Bot: helper")
                            subject_tasks = [process_pwwp_subject(session, subject, selected_batch_id, selected_batch_name, zipf, json_data, all_urls, headers) for subject in subjects]
                            await asyncio.gather(*subject_tasks)

                        json_data[selected_batch_name]["Telegram Bot"] = {"Extractor Bot" : "helper" }
                        file_json= f"{clean_file_name}.json"
                        with open(file_json, 'w') as f1:
                            json.dump(json_data, f1, indent=4)

                        combined_urls = []
                        for subject in subjects:
                            subject_id = subject.get("_id")
                            chapters = await get_pwwp_all_chapters(session, selected_batch_id, subject_id, headers)
                            for chapter in chapters:
                                chapter_id = chapter["_id"]
                                url_collection_key = f"{subject_id}-{chapter_id}"
                                combined_urls.extend(all_urls[url_collection_key])
                                
                        filen = f"{clean_file_name}.txt"
                        with open(filen, 'w', encoding='utf-8') as f1:
                            f1.write('\n'.join(combined_urls))

                        end_time = time.time()
                        response_time = end_time - start_time
                        minutes = int(response_time // 60)
                        seconds = int(response_time % 60)

                        if minutes == 0:
                            if seconds < 1:
                                formatted_time = f"{response_time:.2f} seconds"
                            else:
                                formatted_time = f"{seconds} seconds"
                        else:
                            formatted_time = f"{minutes} minutes {seconds} seconds"

                        await editable.delete(True)
                        total, pdfs, videos = count_urls(filen)

                        caption = (
                            f"📌 Batch Details:\n"
                            f"┌───📚 Batch: {selected_batch_name}\n"
                            f"└──────────────────────────\n\n"
                            f"📂 Batch Info:\n"
                            f"┌───📲 Application: Physics Wallah\n"
                            f"│    🌀 Batch ID: {selected_batch_id}\n"
                            f"└──────────────────────────\n\n"
                            f"📂 Content Overview:\n"
                            f"┌───🔗 Total Links: {total}\n"
                            f"│    ├ 🎥 Videos: {videos} 📹\n"
                            f"│    └ 📄 PDFs: {pdfs} ❌\n"
                            f"└──────────────────────────\n\n"
                            f"🔒 Security Notice:\n"
                            f"┌───🔹 All URLs are encrypted. 🔑\n"
                            f"│    🔹 Use our bot to upload. 🤖\n"
                            f"└──────────────────────────"
                        )

                        files = [f"{clean_file_name}.{ext}" for ext in ["txt", "json"]]
                        for file in files:
                            file_ext = os.path.splitext(file)[1][1:]
                            try: 
                                with open(file, 'rb') as f:
                                    doc = await m.reply_document(document=f, caption=caption, file_name=f"{clean_batch_name}.{file_ext}", thumb=image)
                            except FileNotFoundError:
                                logging.error(f"File not found: {file}")
                            except Exception as e:
                                logging.exception(f"Error sending document {file}:")
                            finally:
                                try:
                                    os.remove(file)
                                except OSError as e:
                                    logging.error(f"Error deleting {file}: {e}")
                    else:
                        raise Exception(f"Error fetching batch details: {batch_details.get('message')}")
                else:
                    raise Exception("Invalid batch index.")
            else:
                raise Exception("No batches found for the given search name.")

        except Exception as e:
            logging.exception(f"An unexpected error occurred: {e}")
            try:
                await editable.edit(f"**Error : {e}**")
            except Exception as ee:
                logging.error(f"Failed to send error message to user in callback: {ee}")
        finally:
            if session:
                await session.close()
            await CONNECTOR.close()
